{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "**<span style=\"color:green\">Execution time = 38 minutes </span>**\n",
    "\n",
    "Code below computes the model performance measures using the document embeddings.\n",
    "\n",
    "Document embeddings are average of word embeddings per document (a single tweet).\n",
    "\n",
    "Code uses **Random Forest** and **Gradient Boosting** computed after *grid-search.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base libraries for mathematical operations, dataframes, time and plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "table.dataframe td, table.dataframe th {\n",
       "    border: 1px  black solid !important;\n",
       "  color: black !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starting time\n",
    "t0 = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Hate','Offensive','Neutral']\n",
    "path = \"datasets/balanced_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#sikh #temple vandalised in in #calgary, #wso ...</td>\n",
       "      <td>sikh temple vandalised in in calgary wso conde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@user @user @user on flipside of  , praise @us...</td>\n",
       "      <td>on flipside of praise for reminder that reales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @KatiePavlich: Charlie Crist doesn't have a...</td>\n",
       "      <td>charlie crist doesn t have any more political ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @RihannaHasAids: aight game over. dykes had...</td>\n",
       "      <td>aight game over dykes had to ruin it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                              tweet  \\\n",
       "0       0  #sikh #temple vandalised in in #calgary, #wso ...   \n",
       "1       2  @user @user @user on flipside of  , praise @us...   \n",
       "2       2  RT @KatiePavlich: Charlie Crist doesn't have a...   \n",
       "3       0  @user you might be a libtard if... #libtard  #...   \n",
       "4       0  RT @RihannaHasAids: aight game over. dykes had...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  sikh temple vandalised in in calgary wso conde...  \n",
       "1  on flipside of praise for reminder that reales...  \n",
       "2  charlie crist doesn t have any more political ...  \n",
       "3  you might be a libtard if libtard sjw liberal ...  \n",
       "4               aight game over dykes had to ruin it  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the dataset\n",
    "data = pd.read_csv(path)\n",
    "# drop any rows with null (after preprocessing)\n",
    "data = data.dropna()\n",
    "# print first 5 rows of the data set\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets (2:1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.clean_tweet, data.labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('../wordemb/helper/glove/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coeff = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] = coeff\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_vec(text_data):\n",
    "    ''' Input: Document (tweet) dataset\n",
    "    \n",
    "        Document embedding is computed per tweet as average of word embedding\n",
    "        \n",
    "        Output: Array containing document embedding of entire dataset\n",
    "    '''\n",
    "    # doc_embedding collects document vector for each tweet\n",
    "    doc_embedding = []\n",
    "    for text in text_data:\n",
    "        # word counter for number of word per tweet\n",
    "        word_count = 0\n",
    "        # initialize an empty word embedding vector \n",
    "        word_embedding = np.zeros(300)\n",
    "        for word in text.split():\n",
    "            try:\n",
    "                # extract word vector from GloVe dataset\n",
    "                word_embedding += embeddings_index.get(word)\n",
    "                # Increase word counter by one\n",
    "                word_count += 1\n",
    "            except:\n",
    "                 pass\n",
    "        if word_count:\n",
    "            word_embedding /= word_count\n",
    "        else:\n",
    "            word_embedding = np.zeros(300)\n",
    "        doc_embedding.append(word_embedding)\n",
    "    # return document embeddings in array\n",
    "    doc_embedding = np.array(doc_embedding)\n",
    "    return doc_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics_table(test,pred,feature):\n",
    "    '''Inputs:\n",
    "            test = actual labels of test set\n",
    "            pred = model predictions for the the test set\n",
    "            feature = feature name\n",
    "            \n",
    "            Computes macro- and micro- precision, recall and F1-score\n",
    "        Output:\n",
    "            Multi-index data frame with 3 precision measures \n",
    "    '''\n",
    "    temp_dict = {'Performance':['Precision','Recall','F1-Score']}\n",
    "    averages = ['micro','macro']\n",
    "    for average in averages:\n",
    "        p,r,f,_ = prfs(test,pred,average = average)\n",
    "        temp_dict[average]= np.round((p,r,f),4)\n",
    "    temp_df = pd.DataFrame(temp_dict)\n",
    "    temp_df = pd.melt(temp_df, id_vars=['Performance'], value_vars=averages,\n",
    "                        var_name='Metric', value_name=feature).set_index(['Metric','Performance'])\n",
    "    temp_df = temp_df.rename_axis([None,'Performance Measures'])\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = embedded_vec(X_train)\n",
    "x_test = embedded_vec(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                       max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Total Time for Random Forest fit on document embeddings is 138.0 sec\n"
     ]
    }
   ],
   "source": [
    "# Initiate Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, bootstrap=False, max_depth = 100)\n",
    "    \n",
    "print('=='*30)\n",
    "print(rf_clf)\n",
    "ta = time()\n",
    "rf_clf.fit(x_train, Y_train)\n",
    "y_pred_rf = rf_clf.predict(x_test)\n",
    "tb = time()-ta\n",
    "print('\\nTotal Time for Random Forest fit on document embeddings is {} sec'.format(np.round(tb)))\n",
    "\n",
    "tbl = performance_metrics_table(Y_test,y_pred_rf,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=800,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Total time for Gradient Boosting fit on document embeddings is 2122.0 sec \n"
     ]
    }
   ],
   "source": [
    "# Initiate Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=800, max_depth = 5)\n",
    "print('=='*30)\n",
    "print(gb_clf)\n",
    "ta = time()\n",
    "gb_clf.fit(x_train, Y_train)\n",
    "y_pred_gb = gb_clf.predict(x_test)\n",
    "tb = time()-ta\n",
    "print('\\nTotal time for Gradient Boosting fit on document embeddings is {} sec '.format(np.round(tb)))\n",
    "\n",
    "tbl = tbl.join(performance_metrics_table(Y_test,y_pred_gb,'Gradient Boosting'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Peformance Measures for Document Embedding ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Performance Measures</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">micro</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">macro</th>\n",
       "      <th>Precision</th>\n",
       "      <td>0.7891</td>\n",
       "      <td>0.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.7892</td>\n",
       "      <td>0.8187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.7867</td>\n",
       "      <td>0.8175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Random Forest  Gradient Boosting\n",
       "      Performance Measures                                  \n",
       "micro Precision                    0.7884             0.8182\n",
       "      Recall                       0.7884             0.8182\n",
       "      F1-Score                     0.7884             0.8182\n",
       "macro Precision                    0.7891             0.8180\n",
       "      Recall                       0.7892             0.8187\n",
       "      F1-Score                     0.7867             0.8175"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print performance metric table for Random Forests for the feature list\n",
    "print('=='*10,'Peformance Measures for Document Embedding','=='*10)\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Total Code Execution Time: 2286.0 seconds\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "code_time = t1 - t0\n",
    "print(\"==\"*30)\n",
    "print('Total Code Execution Time: {} seconds'. format(np.round(code_time),4))\n",
    "print(\"==\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47619047619047616"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.84-0.44)/0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
