{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "**Warning: <span style=\"color:red\">high execution time (several hours) </span>**\n",
    "\n",
    "Code below computes the model performance measures for the following input features:\n",
    "\n",
    "    - Character Bi-grams\n",
    "    - Character Tri-grams\n",
    "    - Character 4-grams\n",
    "    - Character 5-grams\n",
    "    - Character 6-grams\n",
    "    - Character 7-grams\n",
    "    - Character 8-grams\n",
    "    - Word Uni-gram\n",
    "    - Word Bi-grams\n",
    "    - Word Tri-grams\n",
    "\n",
    "Code uses **Random Forest** and **Gradient Boosting** computed after *grid-search.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base libraries for mathematical operations, dataframes, time and plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starting time\n",
    "t0 = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Hate','Offensive','Neutral']\n",
    "path = \"datasets/balanced_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the dataset\n",
    "data = pd.read_csv(path)\n",
    "# drop any rows with null (after preprocessing)\n",
    "data = data.dropna()\n",
    "# print first 5 rows of the data set\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets (2:1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.clean_tweet, data.labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['char bi-gram','char tri-gram', 'char 4-gram',\n",
    "                'char 5-gram', 'char 6-gram', 'char 7-gram','char 8-gram',\n",
    "                'word uni-gram','word bi-gram','word tri-gram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_info(feature):\n",
    "    ''' \n",
    "    Input: Feature\n",
    "    Steps:\n",
    "        Split each feature at whitespaces and hyphens and convert into lower case\n",
    "        Set analyzer to 0th element of the split list 'char'/'word'\n",
    "        Convert 1st element into numerical value\n",
    "        Convert words like uni-1, bi-2, tri-3\n",
    "    Output: analyzer = word/char\n",
    "            N = range of N-grams\n",
    "    '''\n",
    "    token = re.split(r'\\s|-', feature)\n",
    "    analyzer = token[0]\n",
    "    \n",
    "    temp_dict = {'uni':1, 'bi': 2, 'tri': 3}\n",
    "    \n",
    "    if token[1] in temp_dict:\n",
    "        N = temp_dict[token[1]]\n",
    "    else:\n",
    "        N = np.int(token[1])\n",
    "    return (analyzer, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics_table(test,pred,feature):\n",
    "    '''Inputs:\n",
    "            test = actual labels of test set\n",
    "            pred = model predictions for the the test set\n",
    "            feature = feature name\n",
    "            \n",
    "            Computes macro- and micro- precision, recall and F1-score\n",
    "        Output:\n",
    "            Multi-index data frame with 3 precision measures \n",
    "    '''\n",
    "    temp_dict = {'Performance':['Precision','Recall','F1-Score']}\n",
    "    averages = ['micro','macro']\n",
    "    for average in averages:\n",
    "        p,r,f,_ = prfs(test,pred,average = average)\n",
    "        temp_dict[average]= np.round((p,r,f),4)\n",
    "    temp_df = pd.DataFrame(temp_dict)\n",
    "    temp_df = pd.melt(temp_df, id_vars=['Performance'], value_vars=averages,\n",
    "                        var_name='Metric', value_name=feature).set_index(['Metric','Performance'])\n",
    "    temp_df = temp_df.rename_axis([None,'Performance Measures'])\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Each feature fit the decision tree models.\n",
    "for i,feature in enumerate(feature_list):  \n",
    "    # Extract infro from each feature  \n",
    "    analyzer,N_range = feature_info(feature)\n",
    "    # Vectorize the text data\n",
    "    vectorizer = TfidfVectorizer(analyzer = analyzer,ngram_range = (N_range,N_range))\n",
    "    x_train = vectorizer.fit_transform(X_train)\n",
    "    x_test = vectorizer.transform(X_test)\n",
    "    #########################################\n",
    "    # Initiate Random Forest Classifier\n",
    "    rf_clf = RandomForestClassifier(n_estimators=500, bootstrap=False, max_depth = 100)\n",
    "    \n",
    "    print('=='*30)\n",
    "    ta = time()\n",
    "    rf_clf.fit(x_train, Y_train)\n",
    "    y_pred_rf = rf_clf.predict(x_test)\n",
    "    tb = time()-ta\n",
    "    print('Total Time for Random Forest fit on {} is {} sec'.format(feature.lower(), np.round(tb)))\n",
    "    #########################################\n",
    "    # Initiate Gradient Boosting Classifier\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=800, max_depth = 5)\n",
    "    print('..'*30)\n",
    "    ta = time()\n",
    "    gb_clf.fit(x_train, Y_train)\n",
    "    y_pred_gb = gb_clf.predict(x_test)\n",
    "    tb = time()-ta\n",
    "    print('Total time for Gradient Boosting fit on {} is {} sec '.format(feature.lower(), np.round(tb)))\n",
    "    #########################################\n",
    "    # Store the results from individual classifier per \n",
    "    if i==0:\n",
    "        # Tables for storing performance metrics\n",
    "        rf_tbl = performance_metrics_table(Y_test,y_pred_rf,feature)\n",
    "        gb_tbl = performance_metrics_table(Y_test,y_pred_gb,feature)\n",
    "    else:\n",
    "        # Join together tables for new features\n",
    "        rf_tbl = rf_tbl.join(performance_metrics_table(Y_test,y_pred_rf,feature))\n",
    "        gb_tbl = gb_tbl.join(performance_metrics_table(Y_test,y_pred_gb,feature))\n",
    "        \n",
    "\n",
    "print('=='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print performance metric table for Random Forests for the feature list\n",
    "print('=='*22,'Random Forest Classifier','=='*22)\n",
    "rf_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print performance metric table for Gradient Boosting for the feature list\n",
    "print('=='*21,'Gradient Boosting Classifier','=='*21)\n",
    "gb_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time()\n",
    "code_time = t1 - t0\n",
    "print(\"==\"*30)\n",
    "print('Total Code Execution Time: {} seconds'. format(np.round(code_time),4))\n",
    "print(\"==\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
